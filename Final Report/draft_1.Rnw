@
\documentclass[a4paper,10pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{fontenc}
\usepackage{graphicx}
\usepackage{fancyhdr}
\pagestyle{fancy}

\date{\today}

\begin{document}
\SweaveOpts{concordance=TRUE}


% Title Page
\begin{titlepage}
\begin{center}
% Title

\textsc{\Large SPM4500: Fundamentals of Data Analytics - Final Assignment Report }\\[6cm]

{ \bfseries \Large Performance of various Data Analytics Techniques on Kaggle's Problem Set `Titanic: Machine Learning from Disaster' \\[6cm] }

% Author and supervisor
\begin{minipage}{0.6\textwidth}
\emph{Authors:}\\
\begin{flushleft} \large
Nidhi \textsc{Singh}\\
4242246 \\
n.singh-2@student.tudelft.nl\\
MSc. Computer Science\\
\end{flushleft}

\begin{flushright} \large
K. \textsc{Chaitanya Akundi}\\
4242246 \\
k.c.akundi@student.tudelft.nl\\
MSc. Computer Science\\
\end{flushright}

\end{minipage}

\end{center}
\end{titlepage}

\listoffigures

\chapter*{Titanic Data Set}
\section*{Problem Description}
For our final assignment, we have taken up a challenge from Kaggle `Predict survival on the Titanic'. The dataset includes details of people who travelled on RMS Titanic which sank in 1912 killing 1502 out of 2224 passengers.
The aim of the Kaggle challenge is to complete the analysis of what sorts of people were likely to survive. In order to do so, we will apply different predictive models to the dataset and will finally evaluate their performance against each other. Kaggle also supports Leaderboards which evaluate the submitted results, but since this evaluation is based on only 50\% of the test data, it makes sense to do performance evaluation of all the models.

\ Since we are given both training and test data set, this problem's predictive models will fall under the umbrella of Supervised Learning Algorithms. Also we have to decide whether a passenger survived or not, this makes it a classic Classification problem.

\section*{Data Exploration}
Before diving deep into prediction making on test data, we will explore the dataset. We are given two sets of data, training (data containing attributes and known outcomes [survived or perished] for a subset of the passengers) and test (data containing attributes without outcomes for a subset of passengers).The given training data set has 891 observations of following 12 variables:
\begin{itemize}
  \item PassengerId - Unique generated Id for each passenger
  \item Survived - Survival(0 = No; 1 = Yes)
  \item Pclass - Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)
  \item Name - Name of the person
  \item sex - Sex 
  \item Age - Age
  \item Sibsp - Number of Siblings/Spouses Aboard
  \item Parch - Number of Parents/Children Aboard
  \item Ticket - Ticket Number
  \item Fare - Passenger Fare
  \item Cabin - Cabin in the ship
  \item Embarked - Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)
  
\end{itemize}

<<echo=FALSE>>=
options(width=45)
train_csv <- read.csv('/home/nidhi/Courses//TUDelft-Data Analytics/Kaggle:Titanic problem/train.csv')
@
Let us start by looking at the type of these variables
<<>>=
str(train_csv)
@
Here Factor refers to categorical data, since all the names are unique, we have 891 levels equal to number of observations.
<<>>=
prop.table(table(train_csv$Survived))
@
This shows that 61.6\% of the passengers perished and only 38.3\% survived.
Running the same code for Sex, we find 35.2\% females and 64.7\% in the training data set.
<<>>=
summary(train_csv$Age)
@
Summary results on Age shows that this variable is missing for 177 passengers and the minimum age is 0.42 or 5 months and maximum is 80, while 90\% of the passengers were below 50.
\section*{Feature Engineering}

\chapter{Prediction Models}
Since the `Predict survival on the Titanic' challenge is a classification problem, we will start with ANOVA and Linear Classifiers and then go further with methods like Descision trees, Random Forests and Ensembles of classifiers. In the following sections we will explore each model in detail and will also report its evaluation on Kaggle.

\section{ANOVA}


\end{document}
